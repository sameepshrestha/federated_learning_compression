{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PDPvFtAaIxXo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e922c185-b4ab-4708-8814-c9c0757cd3d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for data load\n",
        "import os\n",
        "\n",
        "# for reading and processing images\n",
        "import imageio\n",
        "from PIL import Image\n",
        "\n",
        "# for visualizations\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np # for using np arrays\n",
        "\n",
        "# for bulding and running deep learning model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "9e-6kE9KJCfC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FPB_O_nbJETZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nziMCqauEK3x"
      },
      "source": [
        "def LoadData (input_dir, target_dir):\n",
        "    \"\"\"\n",
        "    Looks for relevant filenames in the shared path\n",
        "    Returns 2 lists for original and masked files respectively\n",
        "\n",
        "    \"\"\"\n",
        "    input_img_paths =sorted([os.path.join(input_dir , fname )for fname in os.listdir(input_dir) if fname.endswith(\".jpg\")])\n",
        "    target_img_paths = sorted([os.path.join(target_dir , fname) for fname in os.listdir(target_dir) if fname.endswith(\".png\") and not fname.startswith(\".\")])\n",
        "    # Read the images folder like a list\n",
        "\n",
        "\n",
        "    return input_img_paths, target_img_paths"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def PreprocessData(img, mask, target_shape_img, target_shape_mask, path1, path2):\n",
        "    \"\"\"\n",
        "    Processes the images and mask present in the shared list and path\n",
        "    Returns a NumPy dataset with images as 3-D arrays of desired size\n",
        "    Please note the masks in this dataset have only one channel\n",
        "    \"\"\"\n",
        "    # Pull the relevant dimensions for image and mask\n",
        "    m = len(img)                     # number of images\n",
        "    i_h,i_w,i_c = target_shape_img   # pull height, width, and channels of image\n",
        "    m_h,m_w,m_c = target_shape_mask  # pull height, width, and channels of mask\n",
        "\n",
        "    # Define X and Y as number of images along with shape of one image\n",
        "    X = np.zeros((m,i_h,i_w,i_c), dtype=np.float32)\n",
        "    y = np.zeros((m,m_h,m_w,m_c), dtype=np.int32)\n",
        "\n",
        "    # Resize images and masks\n",
        "    for file in img:\n",
        "        # convert image into an array of desired shape (3 channels)\n",
        "        index = img.index(file)\n",
        "        path = os.path.join(path1, file)\n",
        "        single_img = Image.open(path).convert('RGB')\n",
        "        single_img = single_img.resize((i_h,i_w))\n",
        "        single_img = np.reshape(single_img,(i_h,i_w,i_c))\n",
        "        single_img = single_img/256.\n",
        "        X[index] = single_img\n",
        "\n",
        "        # convert mask into an array of desired shape (1 channel)\n",
        "        single_mask_ind = mask[index]\n",
        "        path = os.path.join(path2, single_mask_ind)\n",
        "        single_mask = Image.open(path)\n",
        "        single_mask = single_mask.resize((m_h, m_w))\n",
        "        single_mask = np.reshape(single_mask,(m_h,m_w,m_c))\n",
        "        single_mask = single_mask - 1 # to ensure classes #s start from 0\n",
        "        y[index] = single_mask\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "tr8pGFZdJMZP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = (128 , 128)\n",
        "def path_to_img(path):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_jpeg(img , channels=3)\n",
        "    img = tf.image.resize(img , img_size)\n",
        "    img = tf.cast(img , tf.float32)\n",
        "    return img\n",
        "def path_to_target(path):\n",
        "    img = tf.io.read_file(path )\n",
        "    img = tf.image.decode_png(img ,channels=1 )\n",
        "    img = tf.image.resize(img , img_size)\n",
        "    img = tf.cast(img , tf.uint8) - 1\n",
        "    return img\n",
        "def map_fn(img_path , target_path):\n",
        "    img = path_to_img(img_path)\n",
        "    mask = path_to_target(target_path)\n",
        "    return img , mask\n",
        "num_valid_samples =1000"
      ],
      "metadata": {
        "id": "YOQJg2aFJh1w"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def EncoderMiniBlock(inputs, n_filters=32, dropout_prob=0.3, max_pooling=True,name=\"name\"):\n",
        "    \"\"\"\n",
        "    This block uses multiple convolution layers, max pool, relu activation to create an architecture for learning.\n",
        "    Dropout can be added for regularization to prevent overfitting.\n",
        "    The block returns the activation values for next layer along with a skip connection which will be used in the decoder\n",
        "    \"\"\"\n",
        "    conv = Conv2D(n_filters,\n",
        "                  3,   # Kernel size\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  kernel_initializer='HeNormal', name = name+\"1\")(inputs)\n",
        "    conv = Conv2D(n_filters,\n",
        "                  3,   # Kernel size\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  kernel_initializer='HeNormal', name = name+\"2\")(conv)\n",
        "\n",
        "    conv = BatchNormalization()(conv, training=False)\n",
        "    if dropout_prob > 0:\n",
        "        conv = tf.keras.layers.Dropout(dropout_prob)(conv)\n",
        "    if max_pooling:\n",
        "        next_layer = tf.keras.layers.MaxPooling2D(pool_size = (2,2))(conv)\n",
        "    else:\n",
        "        next_layer = conv\n",
        "    skip_connection = conv\n",
        "\n",
        "    return next_layer, skip_connection\n",
        "def DecoderMiniBlock(prev_layer_input, skip_layer_input, n_filters=32, name=\"name\"):\n",
        "    \"\"\"\n",
        "    Decoder Block first uses transpose convolution to upscale the image to a bigger size and then,\n",
        "    merges the result with skip layer results from encoder block\n",
        "    Adding 2 convolutions with 'same' padding helps further increase the depth of the network for better predictions\n",
        "    The function returns the decoded layer output\n",
        "    \"\"\"\n",
        "    up = Conv2DTranspose(\n",
        "                n_filters,\n",
        "                (3,3),    # Kernel size\n",
        "                strides=(2,2),\n",
        "                padding='same',name=name+\"transpose\")(prev_layer_input)\n",
        "\n",
        "    conv = Conv2D(n_filters,\n",
        "                3,     # Kernel size\n",
        "                activation='relu',\n",
        "                padding='same',\n",
        "                kernel_initializer='HeNormal', name = name +\"1\")(up)\n",
        "    conv = Conv2D(n_filters,\n",
        "                3,   # Kernel size\n",
        "                activation='relu',\n",
        "                padding='same',\n",
        "                kernel_initializer='HeNormal', name = name +\"2\")(conv)\n",
        "    return conv\n",
        "\n",
        "def UNetCompiled(input_size=(128, 128, 3), n_filters=32, n_classes=3):\n",
        "\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    cblock1 = EncoderMiniBlock(inputs, n_filters,dropout_prob=0, max_pooling=True, name = \"cblock1\")\n",
        "    cblock2 = EncoderMiniBlock(cblock1[0],n_filters*2,dropout_prob=0, max_pooling=True,name = \"cblock2\")\n",
        "    cblock3 = EncoderMiniBlock(cblock2[0], n_filters*4,dropout_prob=0, max_pooling=True, name = \"cblock3\")\n",
        "    cblock4 = EncoderMiniBlock(cblock3[0], n_filters*8,dropout_prob=0.3, max_pooling=True,name = \"cblock4\")\n",
        "    cblock5 = EncoderMiniBlock(cblock4[0], n_filters*16, dropout_prob=0.3, max_pooling=False,name=\"cblock5\")\n",
        "\n",
        "    ublock6 = DecoderMiniBlock(cblock5[0], cblock4[1],  n_filters * 8, name=\"ublock6\")\n",
        "    ublock7 = DecoderMiniBlock(ublock6, cblock3[1],  n_filters * 4,name=\"ublock7\")\n",
        "    ublock8 = DecoderMiniBlock(ublock7, cblock2[1],  n_filters * 2,name=\"ublock8\")\n",
        "    ublock9 = DecoderMiniBlock(ublock8, cblock1[1],  n_filters,name=\"ublock9\")\n",
        "    conv9 = Conv2D(n_filters,\n",
        "                3,\n",
        "                activation='relu',\n",
        "                padding='same',\n",
        "                kernel_initializer='he_normal',name=\"conv9\")(ublock9)\n",
        "\n",
        "    conv10 = Conv2D(n_classes, 1, padding='same',name=\"conv10\")(conv9)\n",
        "\n",
        "    # Define the model\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=conv10)\n",
        "\n",
        "    return model\n",
        "model= UNetCompiled(input_size=(128, 128, 3), n_filters=32, n_classes=3)"
      ],
      "metadata": {
        "id": "sIvfjwybJhcj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_names = [\n",
        " 'cblock11',\n",
        " 'cblock12',\n",
        " 'cblock21',\n",
        " 'cblock22',\n",
        " 'cblock31',\n",
        " 'cblock32',\n",
        " 'cblock41',\n",
        " 'cblock42',\n",
        " 'cblock51',\n",
        " 'cblock52',\n",
        " 'ublock6transpose',\n",
        " 'ublock61',\n",
        " 'ublock62',\n",
        " 'ublock7transpose',\n",
        " 'ublock71',\n",
        " 'ublock72',\n",
        " 'ublock8transpose',\n",
        " 'ublock81',\n",
        " 'ublock82',\n",
        " 'ublock9transpose',\n",
        " 'ublock91',\n",
        " 'ublock92',\n",
        " 'conv9',\n",
        " 'conv10']"
      ],
      "metadata": {
        "id": "q2Mt7JIaJhGi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load images and masks\n",
        "path1 = '/content/drive/MyDrive/segmentation/images'\n",
        "path2 = '/content/drive/MyDrive/segmentation/annotations/trimaps'\n",
        "img, mask = LoadData(path1, path2)  # LoadData should return lists of image and mask paths\n"
      ],
      "metadata": {
        "id": "FE5Sn_dHRWYQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_trainable_layers(model, layers_to_train):\n",
        "    \"\"\"\n",
        "    Set only specific layers to be trainable.\n",
        "\n",
        "    Args:\n",
        "    model: The model whose layers are to be modified.\n",
        "    layers_to_train: A list of layer names to be set as trainable.\n",
        "    \"\"\"\n",
        "    for layer in model.layers:\n",
        "        if layer.name in layers_to_train:\n",
        "            layer.trainable = True\n",
        "        else:\n",
        "            layer.trainable = False\n"
      ],
      "metadata": {
        "id": "C8pEwetb_V-u"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "\n",
        "# Number of clients\n",
        "num_clients = 5\n",
        "\n",
        "# Shuffle the dataset and divide it into num_clients parts\n",
        "client_data_indices = np.array_split(np.arange(len(img)), num_clients)\n",
        "\n",
        "# Create datasets for each client\n",
        "client_datasets = []\n",
        "for indices in client_data_indices:\n",
        "    client_images = np.array(img)[indices]\n",
        "    client_masks = np.array(mask)[indices]\n",
        "\n",
        "    # Create TensorFlow datasets for each client\n",
        "    client_dataset = tf.data.Dataset.from_tensor_slices((client_images, client_masks))\n",
        "    client_dataset = client_dataset.map(map_fn).batch(64).prefetch(1)\n",
        "    client_datasets.append(client_dataset)\n"
      ],
      "metadata": {
        "id": "By4Hjs1l_aYH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "global_model = UNetCompiled(input_size=(128, 128, 3), n_filters=32, n_classes=3)\n",
        "all_layer_names = [layer.name for layer in global_model.layers]\n",
        "\n",
        "def train_client_model(client_dataset, client_id, layers_to_train):\n",
        "    local_model = tf.keras.models.clone_model(global_model)\n",
        "    local_model.set_weights(global_model.get_weights())  # Copy global weights to the local model\n",
        "    set_trainable_layers(local_model, layers_to_train)\n",
        "    local_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                        metrics=['accuracy'])\n",
        "    local_model.fit(client_dataset, epochs=1)\n",
        "    print(f\"Client {client_id} finished training.\")\n",
        "    return local_model.get_weights(), layers_to_train\n"
      ],
      "metadata": {
        "id": "yYcc6t0APGCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def federated_averaging(client_weights, client_layers):\n",
        "    new_weights = [np.zeros_like(w) for w in client_weights[0]]\n",
        "    for client_weight, layers_to_train in zip(client_weights, client_layers):\n",
        "        for i, layer_name in enumerate(all_layer_names):\n",
        "            if layer_name in layers_to_train:\n",
        "                new_weights[i] += client_weight[i]\n",
        "    new_weights = [w / len(client_weights) if all_layer_names[i] in set(sum(client_layers, [])) else w\n",
        "                   for i, w in enumerate(new_weights)]\n",
        "    return new_weights\n"
      ],
      "metadata": {
        "id": "kfZMBS0BPcof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_rounds = 10\n",
        "\n",
        "for round_num in range(num_rounds):\n",
        "    print(f\"Round {round_num + 1}/{num_rounds}\")\n",
        "\n",
        "    layers_to_train = random.sample(all_layer_names, 4)  # Example: select 4 random layers\n",
        "    layers_to_train.extend([\"conv9\", \"conv10\"])  # Always train specific layers\n",
        "    client_weights = []\n",
        "    client_layers = []\n",
        "    for client_id, client_dataset in enumerate(client_datasets):\n",
        "        client_weight, trained_layers = train_client_model(client_dataset, client_id, layers_to_train)\n",
        "        client_weights.append(client_weight)\n",
        "        client_layers.append(trained_layers)\n",
        "\n",
        "    avg_weights = federated_averaging(client_weights, client_layers)\n",
        "    global_model.set_weights(avg_weights)\n",
        "\n",
        "    print(f\"Completed Round {round_num + 1}. Global model updated with layers: {layers_to_train}\")\n"
      ],
      "metadata": {
        "id": "sk-NkAfDPgj5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}