{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sameepshrestha/federated_learning_compression/blob/main/federated__learning_rough_simulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDPvFtAaIxXo",
        "outputId": "e08770b0-2ab8-4917-c47b-72148805aff4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True) # Set force_remount to True"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHaEK65ldQWu",
        "outputId": "c3cea075-499a-4213-fad0-b6572f93854b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xf yourfile.tar"
      ],
      "metadata": {
        "id": "GU9Uf7ipdwaN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcaae4e1-f033-4c07-e37b-7546f24054ec"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tar: yourfile.tar: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9e-6kE9KJCfC"
      },
      "outputs": [],
      "source": [
        "# for data load\n",
        "import os\n",
        "\n",
        "# for reading and processing images\n",
        "import imageio\n",
        "from PIL import Image\n",
        "\n",
        "# for visualizations\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np # for using np arrays\n",
        "\n",
        "# for bulding and running deep learning model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FPB_O_nbJETZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nziMCqauEK3x"
      },
      "outputs": [],
      "source": [
        "def LoadData (input_dir, target_dir):\n",
        "    \"\"\"\n",
        "    Looks for relevant filenames in the shared path\n",
        "    Returns 2 lists for original and masked files respectively\n",
        "\n",
        "    \"\"\"\n",
        "    input_img_paths =sorted([os.path.join(input_dir , fname )for fname in os.listdir(input_dir) if fname.endswith(\".jpg\")])\n",
        "    target_img_paths = sorted([os.path.join(target_dir , fname) for fname in os.listdir(target_dir) if fname.endswith(\".png\") and not fname.startswith(\".\")])\n",
        "    # Read the images folder like a list\n",
        "\n",
        "\n",
        "    return input_img_paths, target_img_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tr8pGFZdJMZP"
      },
      "outputs": [],
      "source": [
        "def PreprocessData(img, mask, target_shape_img, target_shape_mask, path1, path2):\n",
        "    \"\"\"\n",
        "    Processes the images and mask present in the shared list and path\n",
        "    Returns a NumPy dataset with images as 3-D arrays of desired size\n",
        "    Please note the masks in this dataset have only one channel\n",
        "    \"\"\"\n",
        "    # Pull the relevant dimensions for image and mask\n",
        "    m = len(img)                     # number of images\n",
        "    i_h,i_w,i_c = target_shape_img   # pull height, width, and channels of image\n",
        "    m_h,m_w,m_c = target_shape_mask  # pull height, width, and channels of mask\n",
        "\n",
        "    # Define X and Y as number of images along with shape of one image\n",
        "    X = np.zeros((m,i_h,i_w,i_c), dtype=np.float32)\n",
        "    y = np.zeros((m,m_h,m_w,m_c), dtype=np.int32)\n",
        "\n",
        "    # Resize images and masks\n",
        "    for file in img:\n",
        "        # convert image into an array of desired shape (3 channels)\n",
        "        index = img.index(file)\n",
        "        path = os.path.join(path1, file)\n",
        "        single_img = Image.open(path).convert('RGB')\n",
        "        single_img = single_img.resize((i_h,i_w))\n",
        "        single_img = np.reshape(single_img,(i_h,i_w,i_c))\n",
        "        single_img = single_img/256.\n",
        "        X[index] = single_img\n",
        "\n",
        "        # convert mask into an array of desired shape (1 channel)\n",
        "        single_mask_ind = mask[index]\n",
        "        path = os.path.join(path2, single_mask_ind)\n",
        "        single_mask = Image.open(path)\n",
        "        single_mask = single_mask.resize((m_h, m_w))\n",
        "        single_mask = np.reshape(single_mask,(m_h,m_w,m_c))\n",
        "        single_mask = single_mask - 1 # to ensure classes #s start from 0\n",
        "        y[index] = single_mask\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YOQJg2aFJh1w"
      },
      "outputs": [],
      "source": [
        "img_size = (128 , 128)\n",
        "def path_to_img(path):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_jpeg(img , channels=3)\n",
        "    img = tf.image.resize(img , img_size)\n",
        "    img = tf.cast(img , tf.float32)\n",
        "    return img\n",
        "def path_to_target(path):\n",
        "    img = tf.io.read_file(path )\n",
        "    img = tf.image.decode_png(img ,channels=1 )\n",
        "    img = tf.image.resize(img , img_size)\n",
        "    img = tf.cast(img , tf.uint8) - 1\n",
        "    return img\n",
        "def map_fn(img_path , target_path):\n",
        "    img = path_to_img(img_path)\n",
        "    mask = path_to_target(target_path)\n",
        "    return img , mask\n",
        "num_valid_samples =1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sIvfjwybJhcj"
      },
      "outputs": [],
      "source": [
        "def EncoderMiniBlock(inputs, n_filters=32, dropout_prob=0.3, max_pooling=True,name=\"name\"):\n",
        "    \"\"\"\n",
        "    This block uses multiple convolution layers, max pool, relu activation to create an architecture for learning.\n",
        "    Dropout can be added for regularization to prevent overfitting.\n",
        "    The block returns the activation values for next layer along with a skip connection which will be used in the decoder\n",
        "    \"\"\"\n",
        "    conv = Conv2D(n_filters,\n",
        "                  3,   # Kernel size\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  kernel_initializer='HeNormal', name = name+\"1\")(inputs)\n",
        "    conv = Conv2D(n_filters,\n",
        "                  3,   # Kernel size\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  kernel_initializer='HeNormal', name = name+\"2\")(conv)\n",
        "\n",
        "    conv = BatchNormalization()(conv, training=False)\n",
        "    if dropout_prob > 0:\n",
        "        conv = tf.keras.layers.Dropout(dropout_prob)(conv)\n",
        "    if max_pooling:\n",
        "        next_layer = tf.keras.layers.MaxPooling2D(pool_size = (2,2))(conv)\n",
        "    else:\n",
        "        next_layer = conv\n",
        "    skip_connection = conv\n",
        "\n",
        "    return next_layer, skip_connection\n",
        "def DecoderMiniBlock(prev_layer_input, skip_layer_input, n_filters=32, name=\"name\"):\n",
        "    \"\"\"\n",
        "    Decoder Block first uses transpose convolution to upscale the image to a bigger size and then,\n",
        "    merges the result with skip layer results from encoder block\n",
        "    Adding 2 convolutions with 'same' padding helps further increase the depth of the network for better predictions\n",
        "    The function returns the decoded layer output\n",
        "    \"\"\"\n",
        "    up = Conv2DTranspose(\n",
        "                n_filters,\n",
        "                (3,3),    # Kernel size\n",
        "                strides=(2,2),\n",
        "                padding='same',name=name+\"transpose\")(prev_layer_input)\n",
        "\n",
        "    conv = Conv2D(n_filters,\n",
        "                3,     # Kernel size\n",
        "                activation='relu',\n",
        "                padding='same',\n",
        "                kernel_initializer='HeNormal', name = name +\"1\")(up)\n",
        "    conv = Conv2D(n_filters,\n",
        "                3,   # Kernel size\n",
        "                activation='relu',\n",
        "                padding='same',\n",
        "                kernel_initializer='HeNormal', name = name +\"2\")(conv)\n",
        "    return conv\n",
        "\n",
        "def UNetCompiled(input_size=(128, 128, 3), n_filters=32, n_classes=3):\n",
        "\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    cblock1 = EncoderMiniBlock(inputs, n_filters,dropout_prob=0, max_pooling=True, name = \"cblock1\")\n",
        "    cblock2 = EncoderMiniBlock(cblock1[0],n_filters*2,dropout_prob=0, max_pooling=True,name = \"cblock2\")\n",
        "    cblock3 = EncoderMiniBlock(cblock2[0], n_filters*4,dropout_prob=0, max_pooling=True, name = \"cblock3\")\n",
        "    cblock4 = EncoderMiniBlock(cblock3[0], n_filters*8,dropout_prob=0.3, max_pooling=True,name = \"cblock4\")\n",
        "    cblock5 = EncoderMiniBlock(cblock4[0], n_filters*16, dropout_prob=0.3, max_pooling=False,name=\"cblock5\")\n",
        "\n",
        "    ublock6 = DecoderMiniBlock(cblock5[0], cblock4[1],  n_filters * 8, name=\"ublock6\")\n",
        "    ublock7 = DecoderMiniBlock(ublock6, cblock3[1],  n_filters * 4,name=\"ublock7\")\n",
        "    ublock8 = DecoderMiniBlock(ublock7, cblock2[1],  n_filters * 2,name=\"ublock8\")\n",
        "    ublock9 = DecoderMiniBlock(ublock8, cblock1[1],  n_filters,name=\"ublock9\")\n",
        "    conv9 = Conv2D(n_filters,\n",
        "                3,\n",
        "                activation='relu',\n",
        "                padding='same',\n",
        "                kernel_initializer='he_normal',name=\"conv9\")(ublock9)\n",
        "\n",
        "    conv10 = Conv2D(n_classes, 1, padding='same',name=\"conv10\")(conv9)\n",
        "\n",
        "    # Define the model\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=conv10)\n",
        "\n",
        "    return model\n",
        "model= UNetCompiled(input_size=(128, 128, 3), n_filters=32, n_classes=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "q2Mt7JIaJhGi"
      },
      "outputs": [],
      "source": [
        "layer_names = [\n",
        " 'cblock11',\n",
        " 'cblock12',\n",
        " 'cblock21',\n",
        " 'cblock22',\n",
        " 'cblock31',\n",
        " 'cblock32',\n",
        " 'cblock41',\n",
        " 'cblock42',\n",
        " 'cblock51',\n",
        " 'cblock52',\n",
        " 'ublock6transpose',\n",
        " 'ublock61',\n",
        " 'ublock62',\n",
        " 'ublock7transpose',\n",
        " 'ublock71',\n",
        " 'ublock72',\n",
        " 'ublock8transpose',\n",
        " 'ublock81',\n",
        " 'ublock82',\n",
        " 'ublock9transpose',\n",
        " 'ublock91',\n",
        " 'ublock92',\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FE5Sn_dHRWYQ"
      },
      "outputs": [],
      "source": [
        "# Load images and masks\n",
        "path1 = '/content/drive/MyDrive/segmentation/images'\n",
        "path2 = '/content/drive/MyDrive/segmentation/annotations/trimaps'\n",
        "img, mask = LoadData(path1, path2)  # LoadData should return lists of image and mask paths\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "C8pEwetb_V-u"
      },
      "outputs": [],
      "source": [
        "def set_trainable_layers(model, layers_to_train):\n",
        "    \"\"\"\n",
        "    Set only specific layers to be trainable.\n",
        "\n",
        "    Args:\n",
        "    model: The model whose layers are to be modified.\n",
        "    layers_to_train: A list of layer names to be set as trainable.\n",
        "    \"\"\"\n",
        "    for layer in model.layers:\n",
        "        if layer.name in layers_to_train:\n",
        "            layer.trainable = True\n",
        "        else:\n",
        "            layer.trainable = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-r15-ytRo1VD"
      },
      "outputs": [],
      "source": [
        "def get_layer_weights(model, layers_to_send):\n",
        "    \"\"\"\n",
        "    Extracts the weights of specific layers from the model.\n",
        "\n",
        "    Args:\n",
        "    model: The model from which to extract weights.\n",
        "    layers_to_send: A list of layer names whose weights need to be sent.\n",
        "\n",
        "    Returns:\n",
        "    A dictionary of layer names and their corresponding weights.\n",
        "    \"\"\"\n",
        "    layer_weights = {}\n",
        "    for layer in model.layers:\n",
        "        if layer.name in layers_to_send:\n",
        "            layer_weights[layer.name] = layer.get_weights()\n",
        "    return layer_weights\n",
        "\n",
        "def update_layer_weights(model, received_weights):\n",
        "    \"\"\"\n",
        "    Updates specific layers of the model with received weights.\n",
        "\n",
        "    Args:\n",
        "    model: The model to update.\n",
        "    received_weights: A dictionary of layer names and their new weights.\n",
        "    \"\"\"\n",
        "    # print(avg_weights,\"average weigths\")\n",
        "    for layer in model.layers:\n",
        "        if layer.name in received_weights:\n",
        "            # print(received_weights[layer.name].shape)\n",
        "            layer.set_weights(received_weights[layer.name])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "dw0Xj2pMrq2t"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "num_clients = 4\n",
        "\n",
        "# Shuffle the dataset indices\n",
        "data_indices = np.arange(len(img))  # Create an array of indices corresponding to the dataset\n",
        "np.random.shuffle(data_indices)     # Shuffle the indices\n",
        "\n",
        "# Split the shuffled indices into num_clients parts\n",
        "client_data_indices = np.array_split(data_indices, num_clients)\n",
        "\n",
        "# Create datasets for each client\n",
        "client_datasets = []\n",
        "for indices in client_data_indices:\n",
        "    client_images = np.array(img)[indices]\n",
        "    client_masks = np.array(mask)[indices]\n",
        "\n",
        "    # Create TensorFlow datasets for each client\n",
        "    client_dataset = tf.data.Dataset.from_tensor_slices((client_images, client_masks))\n",
        "    client_dataset = client_dataset.map(map_fn).batch(64).prefetch(1)\n",
        "    client_datasets.append(client_dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QUPL_3UssoTV"
      },
      "outputs": [],
      "source": [
        "# def federated_averaging(client_weights, client_layers):\n",
        "#     \"\"\"\n",
        "#     Performs federated averaging of the weights for specific layers across all clients.\n",
        "\n",
        "#     Args:\n",
        "#     client_weights: A list of dictionaries, each containing layer weights from a client.\n",
        "#     client_layers: A list of lists, each containing layer names that were trained on each client.\n",
        "\n",
        "#     Returns:\n",
        "#     A dictionary of averaged weights for the selected layers.\n",
        "#     \"\"\"\n",
        "#     new_weights = {layer_name: None for layer_name in all_layer_names} #empty weights dictionary\n",
        "#     layer_counts = {layer_name: 0 for layer_name in all_layer_names}\n",
        "\n",
        "#     for client_weight, layers_to_train in zip(client_weights, client_layers):\n",
        "#         for layer_name in layers_to_train:#layers to train will contain layers of all the client which was trained\n",
        "#             if layer_name in client_weight:\n",
        "#                 if new_weights[layer_name] is None:\n",
        "#                     print(len(client_weight[layer_name]))\n",
        "#                     new_weights[layer_name] = client_weight[layer_name][0]\n",
        "#                 else:\n",
        "#                     new_weights[layer_name] += client_weight[layer_name][0]\n",
        "#                 layer_counts[layer_name] += 1\n",
        "#     for layer_name in new_weights:\n",
        "#         if layer_counts[layer_name] > 0:  # Only average layers that were trained\n",
        "#             print(new_weights[layer_name].shape)\n",
        "#             new_weights[layer_name] /= layer_counts[layer_name]\n",
        "\n",
        "#     # Filter out None values for layers that were not trained by any client\n",
        "#     new_weights = {k: v for k, v in new_weights.items() if v is not None}\n",
        "#     print(\"new_weights\",new_weights.keys())\n",
        "#     return new_weights\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def federated_averaging(client_weights, client_layers):\n",
        "    \"\"\"\n",
        "    Performs federated averaging of the weights for specific layers across all clients.\n",
        "\n",
        "    Args:\n",
        "    client_weights: A list of dictionaries, each containing layer weights from a client.\n",
        "    client_layers: A list of lists, each containing layer names that were trained on each client.\n",
        "\n",
        "    Returns:\n",
        "    A dictionary of averaged weights for the selected layers.\n",
        "    \"\"\"\n",
        "    new_weights = {layer_name: None for layer_name in all_layer_names}  # Initialize empty weights dictionary\n",
        "    layer_counts = {layer_name: 0 for layer_name in all_layer_names}    # Initialize counts for each layer\n",
        "\n",
        "    # Iterate over all clients and their corresponding layers to average weights\n",
        "    for client_weight, layers_to_train in zip(client_weights, client_layers):\n",
        "        for layer_name in layers_to_train:\n",
        "            if layer_name in client_weight:\n",
        "                # Initialize the layer weights if not already initialized\n",
        "                if new_weights[layer_name] is None:\n",
        "                    # Create a deep copy of the list of weights for the layer\n",
        "                    new_weights[layer_name] = [np.copy(w) for w in client_weight[layer_name]]\n",
        "                else:\n",
        "                    # Sum the weights across clients for averaging\n",
        "                    for i in range(len(client_weight[layer_name])):\n",
        "                        new_weights[layer_name][i] += client_weight[layer_name][i]\n",
        "                layer_counts[layer_name] += 1\n",
        "\n",
        "    # Average the weights for each layer\n",
        "    for layer_name in new_weights:\n",
        "        if layer_counts[layer_name] > 0:  # Only average layers that were trained\n",
        "            for i in range(len(new_weights[layer_name])):\n",
        "                new_weights[layer_name][i] /= layer_counts[layer_name]\n",
        "\n",
        "    # Filter out None values for layers that were not trained by any client\n",
        "    new_weights = {k: v for k, v in new_weights.items() if v is not None}\n",
        "    print(\"new_weights\", new_weights.keys())\n",
        "    return new_weights\n"
      ],
      "metadata": {
        "id": "weNbVNJvx21n"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the global model\n",
        "import time\n",
        "import random\n",
        "from tensorflow.keras import backend as K\n",
        "import gc\n",
        "global_model = UNetCompiled(input_size=(128, 128, 3), n_filters=32, n_classes=3)\n",
        "global_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                     loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                     metrics=['accuracy'])\n",
        "# List all layer names\n",
        "all_layer_names = [layer.name for layer in global_model.layers]\n",
        "\n",
        "num_rounds = 40\n",
        "\n",
        "# Clients create a local model initially (in round 0)\n",
        "client_models = []\n",
        "for _ in range(len(client_datasets)-1):\n",
        "    client_model = tf.keras.models.clone_model(global_model)\n",
        "    client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n",
        "    client_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                     loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                     metrics=['accuracy'])\n",
        "    client_models.append(client_model)\n",
        "\n",
        "# Initialize the layers to send for the first round\n",
        "layers_to_send = []  # No layers to send initially\n",
        "start_time = time.time()\n",
        "for round_num in range(num_rounds):\n",
        "    print(f\"Round {round_num + 1}/{num_rounds}\")\n",
        "\n",
        "    # Randomly select layers to train for this round\n",
        "    layers_to_train = all_layer_names\n",
        "\n",
        "    # Include specific layers (e.g., output layers) that should always be trained\n",
        "    layers_to_train.append('conv9')\n",
        "    layers_to_train.append('conv10')\n",
        "\n",
        "    # Server sends weights of the selected layers from the previous round to clients\n",
        "    layer_weights_to_send = get_layer_weights(global_model, layers_to_send) if layers_to_send else None\n",
        "\n",
        "    client_weights = []\n",
        "    client_layers = []\n",
        "\n",
        "    # Each client trains its local model with the specified layers\n",
        "    for client_id, client_dataset in enumerate(client_datasets[0:(len(client_datasets)-1)]):\n",
        "        client_model = client_models[client_id]  # Reuse the local model created in round 0\n",
        "\n",
        "        if layer_weights_to_send:\n",
        "            # Update only the relevant layers for this round\n",
        "\n",
        "            update_layer_weights(client_model, layer_weights_to_send)\n",
        "\n",
        "\n",
        "        # Set the specified layers to be trainable\n",
        "        set_trainable_layers(client_model, layers_to_train)\n",
        "\n",
        "        # Compile and train the local model on the client's dataset\n",
        "        client_model.fit(client_dataset, epochs=1)\n",
        "        print(f\"Client {client_id} finished training with layers: {layers_to_train}\")\n",
        "\n",
        "        # Collect only the updated weights for the trained layers\n",
        "        updated_weights = get_layer_weights(client_model, layers_to_train)\n",
        "        client_weights.append(updated_weights)\n",
        "        client_layers.append(layers_to_train)\n",
        "\n",
        "    # Perform federated averaging with only the trained layers\n",
        "    avg_weights = federated_averaging(client_weights, client_layers)\n",
        "    # Update the global model with the averaged weights\n",
        "    update_layer_weights(global_model, avg_weights)\n",
        "\n",
        "    # Prepare the layers for the next round\n",
        "    layers_to_send = layers_to_train\n",
        "\n",
        "    print(f\"Completed Round {round_num + 1}. Global model updated with layers: {layers_to_train}at time\")\n",
        "    print(\"time is \",(time.time()-start_time))\n",
        "    del client_weights, client_layers\n",
        "    K.clear_session()\n",
        "\n",
        "    # Force garbage collection to prevent memory from accumulating\n",
        "    gc.collect()\n",
        "\n",
        "print(\"time is \",(time.time()-start_time))\n",
        "# Evaluate on client 4's dataset\n",
        "loss, accuracy = global_model.evaluate(client_datasets[-1])\n",
        "print(f\"Final evaluation on Client 4's dataset - Loss: {loss}, Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 847
        },
        "id": "hGSCCofvA2Zs",
        "outputId": "18309802-e8ae-4ba4-82a9-1a51ed39da97"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 1/40\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 7s/step - accuracy: 0.5196 - loss: 0.9976\n",
            "Client 0 finished training with layers: ['input_layer_2', 'cblock11', 'cblock12', 'batch_normalization_10', 'max_pooling2d_8', 'cblock21', 'cblock22', 'batch_normalization_11', 'max_pooling2d_9', 'cblock31', 'cblock32', 'batch_normalization_12', 'max_pooling2d_10', 'cblock41', 'cblock42', 'batch_normalization_13', 'dropout_4', 'max_pooling2d_11', 'cblock51', 'cblock52', 'batch_normalization_14', 'dropout_5', 'ublock6transpose', 'ublock61', 'ublock62', 'ublock7transpose', 'ublock71', 'ublock72', 'ublock8transpose', 'ublock81', 'ublock82', 'ublock9transpose', 'ublock91', 'ublock92', 'conv9', 'conv10', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 3s/step - accuracy: 0.5036 - loss: 0.9932\n",
            "Client 1 finished training with layers: ['input_layer_2', 'cblock11', 'cblock12', 'batch_normalization_10', 'max_pooling2d_8', 'cblock21', 'cblock22', 'batch_normalization_11', 'max_pooling2d_9', 'cblock31', 'cblock32', 'batch_normalization_12', 'max_pooling2d_10', 'cblock41', 'cblock42', 'batch_normalization_13', 'dropout_4', 'max_pooling2d_11', 'cblock51', 'cblock52', 'batch_normalization_14', 'dropout_5', 'ublock6transpose', 'ublock61', 'ublock62', 'ublock7transpose', 'ublock71', 'ublock72', 'ublock8transpose', 'ublock81', 'ublock82', 'ublock9transpose', 'ublock91', 'ublock92', 'conv9', 'conv10', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 4s/step - accuracy: 0.4802 - loss: 0.9960\n",
            "Client 2 finished training with layers: ['input_layer_2', 'cblock11', 'cblock12', 'batch_normalization_10', 'max_pooling2d_8', 'cblock21', 'cblock22', 'batch_normalization_11', 'max_pooling2d_9', 'cblock31', 'cblock32', 'batch_normalization_12', 'max_pooling2d_10', 'cblock41', 'cblock42', 'batch_normalization_13', 'dropout_4', 'max_pooling2d_11', 'cblock51', 'cblock52', 'batch_normalization_14', 'dropout_5', 'ublock6transpose', 'ublock61', 'ublock62', 'ublock7transpose', 'ublock71', 'ublock72', 'ublock8transpose', 'ublock81', 'ublock82', 'ublock9transpose', 'ublock91', 'ublock92', 'conv9', 'conv10', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock11', 'cblock12', 'batch_normalization_10', 'max_pooling2d_8', 'cblock21', 'cblock22', 'batch_normalization_11', 'max_pooling2d_9', 'cblock31', 'cblock32', 'batch_normalization_12', 'max_pooling2d_10', 'cblock41', 'cblock42', 'batch_normalization_13', 'dropout_4', 'max_pooling2d_11', 'cblock51', 'cblock52', 'batch_normalization_14', 'dropout_5', 'ublock6transpose', 'ublock61', 'ublock62', 'ublock7transpose', 'ublock71', 'ublock72', 'ublock8transpose', 'ublock81', 'ublock82', 'ublock9transpose', 'ublock91', 'ublock92', 'conv9', 'conv10'])\n",
            "Completed Round 1. Global model updated with layers: ['input_layer_2', 'cblock11', 'cblock12', 'batch_normalization_10', 'max_pooling2d_8', 'cblock21', 'cblock22', 'batch_normalization_11', 'max_pooling2d_9', 'cblock31', 'cblock32', 'batch_normalization_12', 'max_pooling2d_10', 'cblock41', 'cblock42', 'batch_normalization_13', 'dropout_4', 'max_pooling2d_11', 'cblock51', 'cblock52', 'batch_normalization_14', 'dropout_5', 'ublock6transpose', 'ublock61', 'ublock62', 'ublock7transpose', 'ublock71', 'ublock72', 'ublock8transpose', 'ublock81', 'ublock82', 'ublock9transpose', 'ublock91', 'ublock92', 'conv9', 'conv10', 'conv9', 'conv10']at time\n",
            "time is  523.6418330669403\n",
            "Round 2/40\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 492ms/step - accuracy: 0.6734 - loss: 0.7822\n",
            "Client 0 finished training with layers: ['input_layer_2', 'cblock11', 'cblock12', 'batch_normalization_10', 'max_pooling2d_8', 'cblock21', 'cblock22', 'batch_normalization_11', 'max_pooling2d_9', 'cblock31', 'cblock32', 'batch_normalization_12', 'max_pooling2d_10', 'cblock41', 'cblock42', 'batch_normalization_13', 'dropout_4', 'max_pooling2d_11', 'cblock51', 'cblock52', 'batch_normalization_14', 'dropout_5', 'ublock6transpose', 'ublock61', 'ublock62', 'ublock7transpose', 'ublock71', 'ublock72', 'ublock8transpose', 'ublock81', 'ublock82', 'ublock9transpose', 'ublock91', 'ublock92', 'conv9', 'conv10', 'conv9', 'conv10', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 471ms/step - accuracy: 0.6721 - loss: 0.7756\n",
            "Client 1 finished training with layers: ['input_layer_2', 'cblock11', 'cblock12', 'batch_normalization_10', 'max_pooling2d_8', 'cblock21', 'cblock22', 'batch_normalization_11', 'max_pooling2d_9', 'cblock31', 'cblock32', 'batch_normalization_12', 'max_pooling2d_10', 'cblock41', 'cblock42', 'batch_normalization_13', 'dropout_4', 'max_pooling2d_11', 'cblock51', 'cblock52', 'batch_normalization_14', 'dropout_5', 'ublock6transpose', 'ublock61', 'ublock62', 'ublock7transpose', 'ublock71', 'ublock72', 'ublock8transpose', 'ublock81', 'ublock82', 'ublock9transpose', 'ublock91', 'ublock92', 'conv9', 'conv10', 'conv9', 'conv10', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 477ms/step - accuracy: 0.6716 - loss: 0.7789\n",
            "Client 2 finished training with layers: ['input_layer_2', 'cblock11', 'cblock12', 'batch_normalization_10', 'max_pooling2d_8', 'cblock21', 'cblock22', 'batch_normalization_11', 'max_pooling2d_9', 'cblock31', 'cblock32', 'batch_normalization_12', 'max_pooling2d_10', 'cblock41', 'cblock42', 'batch_normalization_13', 'dropout_4', 'max_pooling2d_11', 'cblock51', 'cblock52', 'batch_normalization_14', 'dropout_5', 'ublock6transpose', 'ublock61', 'ublock62', 'ublock7transpose', 'ublock71', 'ublock72', 'ublock8transpose', 'ublock81', 'ublock82', 'ublock9transpose', 'ublock91', 'ublock92', 'conv9', 'conv10', 'conv9', 'conv10', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock11', 'cblock12', 'batch_normalization_10', 'max_pooling2d_8', 'cblock21', 'cblock22', 'batch_normalization_11', 'max_pooling2d_9', 'cblock31', 'cblock32', 'batch_normalization_12', 'max_pooling2d_10', 'cblock41', 'cblock42', 'batch_normalization_13', 'dropout_4', 'max_pooling2d_11', 'cblock51', 'cblock52', 'batch_normalization_14', 'dropout_5', 'ublock6transpose', 'ublock61', 'ublock62', 'ublock7transpose', 'ublock71', 'ublock72', 'ublock8transpose', 'ublock81', 'ublock82', 'ublock9transpose', 'ublock91', 'ublock92', 'conv9', 'conv10'])\n",
            "Completed Round 2. Global model updated with layers: ['input_layer_2', 'cblock11', 'cblock12', 'batch_normalization_10', 'max_pooling2d_8', 'cblock21', 'cblock22', 'batch_normalization_11', 'max_pooling2d_9', 'cblock31', 'cblock32', 'batch_normalization_12', 'max_pooling2d_10', 'cblock41', 'cblock42', 'batch_normalization_13', 'dropout_4', 'max_pooling2d_11', 'cblock51', 'cblock52', 'batch_normalization_14', 'dropout_5', 'ublock6transpose', 'ublock61', 'ublock62', 'ublock7transpose', 'ublock71', 'ublock72', 'ublock8transpose', 'ublock81', 'ublock82', 'ublock9transpose', 'ublock91', 'ublock92', 'conv9', 'conv10', 'conv9', 'conv10', 'conv9', 'conv10']at time\n",
            "time is  581.8863615989685\n",
            "Round 3/40\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 503ms/step - accuracy: 0.7618 - loss: 0.6221\n",
            "Client 0 finished training with layers: ['input_layer_2', 'cblock11', 'cblock12', 'batch_normalization_10', 'max_pooling2d_8', 'cblock21', 'cblock22', 'batch_normalization_11', 'max_pooling2d_9', 'cblock31', 'cblock32', 'batch_normalization_12', 'max_pooling2d_10', 'cblock41', 'cblock42', 'batch_normalization_13', 'dropout_4', 'max_pooling2d_11', 'cblock51', 'cblock52', 'batch_normalization_14', 'dropout_5', 'ublock6transpose', 'ublock61', 'ublock62', 'ublock7transpose', 'ublock71', 'ublock72', 'ublock8transpose', 'ublock81', 'ublock82', 'ublock9transpose', 'ublock91', 'ublock92', 'conv9', 'conv10', 'conv9', 'conv10', 'conv9', 'conv10', 'conv9', 'conv10']\n",
            "\u001b[1m10/29\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 526ms/step - accuracy: 0.7594 - loss: 0.6326 "
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-8c4f1ef2160a>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# Compile and train the local model on the client's dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mclient_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Client {client_id} finished training with layers: {layers_to_train}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_layer_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDbSjGmlTDX2",
        "outputId": "437201fe-d974-4af9-90f7-462b02eb72fa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['input_layer',\n",
              " 'cblock11',\n",
              " 'cblock12',\n",
              " 'batch_normalization',\n",
              " 'max_pooling2d',\n",
              " 'cblock21',\n",
              " 'cblock22',\n",
              " 'batch_normalization_1',\n",
              " 'max_pooling2d_1',\n",
              " 'cblock31',\n",
              " 'cblock32',\n",
              " 'batch_normalization_2',\n",
              " 'max_pooling2d_2',\n",
              " 'cblock41',\n",
              " 'cblock42',\n",
              " 'batch_normalization_3',\n",
              " 'dropout',\n",
              " 'max_pooling2d_3',\n",
              " 'cblock51',\n",
              " 'cblock52',\n",
              " 'batch_normalization_4',\n",
              " 'dropout_1',\n",
              " 'ublock6transpose',\n",
              " 'ublock61',\n",
              " 'ublock62',\n",
              " 'ublock7transpose',\n",
              " 'ublock71',\n",
              " 'ublock72',\n",
              " 'ublock8transpose',\n",
              " 'ublock81',\n",
              " 'ublock82',\n",
              " 'ublock9transpose',\n",
              " 'ublock91',\n",
              " 'ublock92',\n",
              " 'conv9',\n",
              " 'conv10']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "DTchFE-YplqU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "199b9fd1-b6fe-4124-fd96-8c899e30d369"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 1/40\n",
            "Layers to train: ['ublock71', 'ublock62', 'cblock32', 'cblock21']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 566ms/step - accuracy: 0.4366 - loss: 5.2644\n",
            "Client 0 finished training with layers: ['ublock71', 'ublock62', 'cblock32', 'cblock21', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 518ms/step - accuracy: 0.4388 - loss: 5.2227\n",
            "Client 1 finished training with layers: ['ublock71', 'ublock62', 'cblock32', 'cblock21', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 551ms/step - accuracy: 0.4409 - loss: 5.1734\n",
            "Client 2 finished training with layers: ['ublock71', 'ublock62', 'cblock32', 'cblock21', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock21', 'cblock32', 'ublock62', 'ublock71', 'conv9', 'conv10'])\n",
            "Completed Round 1. Global model updated with layers: ['ublock71', 'ublock62', 'cblock32', 'cblock21', 'conv9', 'conv10']at time\n",
            "time is  88.21108031272888\n",
            "Round 2/40\n",
            "Layers to train: ['cblock52', 'cblock12', 'ublock62', 'cblock51']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 461ms/step - accuracy: 0.5416 - loss: 0.9899\n",
            "Client 0 finished training with layers: ['cblock52', 'cblock12', 'ublock62', 'cblock51', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 457ms/step - accuracy: 0.5428 - loss: 0.9900\n",
            "Client 1 finished training with layers: ['cblock52', 'cblock12', 'ublock62', 'cblock51', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 459ms/step - accuracy: 0.5417 - loss: 0.9895\n",
            "Client 2 finished training with layers: ['cblock52', 'cblock12', 'ublock62', 'cblock51', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock12', 'cblock51', 'cblock52', 'ublock62', 'conv9', 'conv10'])\n",
            "Completed Round 2. Global model updated with layers: ['cblock52', 'cblock12', 'ublock62', 'cblock51', 'conv9', 'conv10']at time\n",
            "time is  144.64375853538513\n",
            "Round 3/40\n",
            "Layers to train: ['cblock41', 'ublock71', 'ublock91', 'cblock11']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 460ms/step - accuracy: 0.5720 - loss: 0.9144\n",
            "Client 0 finished training with layers: ['cblock41', 'ublock71', 'ublock91', 'cblock11', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 444ms/step - accuracy: 0.5729 - loss: 0.9130\n",
            "Client 1 finished training with layers: ['cblock41', 'ublock71', 'ublock91', 'cblock11', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 448ms/step - accuracy: 0.5744 - loss: 0.9132\n",
            "Client 2 finished training with layers: ['cblock41', 'ublock71', 'ublock91', 'cblock11', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock11', 'cblock41', 'ublock71', 'ublock91', 'conv9', 'conv10'])\n",
            "Completed Round 3. Global model updated with layers: ['cblock41', 'ublock71', 'ublock91', 'cblock11', 'conv9', 'conv10']at time\n",
            "time is  200.91706347465515\n",
            "Round 4/40\n",
            "Layers to train: ['ublock62', 'cblock41', 'cblock31', 'ublock6transpose']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 465ms/step - accuracy: 0.5884 - loss: 0.8593\n",
            "Client 0 finished training with layers: ['ublock62', 'cblock41', 'cblock31', 'ublock6transpose', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 429ms/step - accuracy: 0.5896 - loss: 0.8578\n",
            "Client 1 finished training with layers: ['ublock62', 'cblock41', 'cblock31', 'ublock6transpose', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 443ms/step - accuracy: 0.5909 - loss: 0.8583\n",
            "Client 2 finished training with layers: ['ublock62', 'cblock41', 'cblock31', 'ublock6transpose', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock31', 'cblock41', 'ublock6transpose', 'ublock62', 'conv9', 'conv10'])\n",
            "Completed Round 4. Global model updated with layers: ['ublock62', 'cblock41', 'cblock31', 'ublock6transpose', 'conv9', 'conv10']at time\n",
            "time is  249.4815638065338\n",
            "Round 5/40\n",
            "Layers to train: ['ublock72', 'ublock8transpose', 'cblock51', 'cblock11']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 456ms/step - accuracy: 0.5931 - loss: 0.8242\n",
            "Client 0 finished training with layers: ['ublock72', 'ublock8transpose', 'cblock51', 'cblock11', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 451ms/step - accuracy: 0.5944 - loss: 0.8229\n",
            "Client 1 finished training with layers: ['ublock72', 'ublock8transpose', 'cblock51', 'cblock11', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 456ms/step - accuracy: 0.5957 - loss: 0.8241\n",
            "Client 2 finished training with layers: ['ublock72', 'ublock8transpose', 'cblock51', 'cblock11', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock11', 'cblock51', 'ublock72', 'ublock8transpose', 'conv9', 'conv10'])\n",
            "Completed Round 5. Global model updated with layers: ['ublock72', 'ublock8transpose', 'cblock51', 'cblock11', 'conv9', 'conv10']at time\n",
            "time is  299.4221456050873\n",
            "Round 6/40\n",
            "Layers to train: ['ublock62', 'cblock42', 'ublock8transpose', 'cblock31']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 463ms/step - accuracy: 0.6890 - loss: 0.7942\n",
            "Client 0 finished training with layers: ['ublock62', 'cblock42', 'ublock8transpose', 'cblock31', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 461ms/step - accuracy: 0.6888 - loss: 0.7932\n",
            "Client 1 finished training with layers: ['ublock62', 'cblock42', 'ublock8transpose', 'cblock31', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 466ms/step - accuracy: 0.6873 - loss: 0.7960\n",
            "Client 2 finished training with layers: ['ublock62', 'cblock42', 'ublock8transpose', 'cblock31', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock31', 'cblock42', 'ublock62', 'ublock8transpose', 'conv9', 'conv10'])\n",
            "Completed Round 6. Global model updated with layers: ['ublock62', 'cblock42', 'ublock8transpose', 'cblock31', 'conv9', 'conv10']at time\n",
            "time is  355.64832377433777\n",
            "Round 7/40\n",
            "Layers to train: ['cblock21', 'ublock72', 'ublock61', 'cblock22']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 468ms/step - accuracy: 0.7108 - loss: 0.7692\n",
            "Client 0 finished training with layers: ['cblock21', 'ublock72', 'ublock61', 'cblock22', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 472ms/step - accuracy: 0.7092 - loss: 0.7705\n",
            "Client 1 finished training with layers: ['cblock21', 'ublock72', 'ublock61', 'cblock22', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 493ms/step - accuracy: 0.7070 - loss: 0.7738\n",
            "Client 2 finished training with layers: ['cblock21', 'ublock72', 'ublock61', 'cblock22', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock21', 'cblock22', 'ublock61', 'ublock72', 'conv9', 'conv10'])\n",
            "Completed Round 7. Global model updated with layers: ['cblock21', 'ublock72', 'ublock61', 'cblock22', 'conv9', 'conv10']at time\n",
            "time is  405.35615134239197\n",
            "Round 8/40\n",
            "Layers to train: ['ublock72', 'ublock6transpose', 'cblock22', 'cblock11']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 468ms/step - accuracy: 0.7211 - loss: 0.7487\n",
            "Client 0 finished training with layers: ['ublock72', 'ublock6transpose', 'cblock22', 'cblock11', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 466ms/step - accuracy: 0.7192 - loss: 0.7510\n",
            "Client 1 finished training with layers: ['ublock72', 'ublock6transpose', 'cblock22', 'cblock11', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 459ms/step - accuracy: 0.7148 - loss: 0.7587\n",
            "Client 2 finished training with layers: ['ublock72', 'ublock6transpose', 'cblock22', 'cblock11', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock11', 'cblock22', 'ublock6transpose', 'ublock72', 'conv9', 'conv10'])\n",
            "Completed Round 8. Global model updated with layers: ['ublock72', 'ublock6transpose', 'cblock22', 'cblock11', 'conv9', 'conv10']at time\n",
            "time is  461.69662952423096\n",
            "Round 9/40\n",
            "Layers to train: ['ublock92', 'cblock22', 'ublock91', 'cblock11']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 463ms/step - accuracy: 0.7276 - loss: 0.7312\n",
            "Client 0 finished training with layers: ['ublock92', 'cblock22', 'ublock91', 'cblock11', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 441ms/step - accuracy: 0.7187 - loss: 0.7486\n",
            "Client 1 finished training with layers: ['ublock92', 'cblock22', 'ublock91', 'cblock11', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 452ms/step - accuracy: 0.7220 - loss: 0.7400\n",
            "Client 2 finished training with layers: ['ublock92', 'cblock22', 'ublock91', 'cblock11', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock11', 'cblock22', 'ublock91', 'ublock92', 'conv9', 'conv10'])\n",
            "Completed Round 9. Global model updated with layers: ['ublock92', 'cblock22', 'ublock91', 'cblock11', 'conv9', 'conv10']at time\n",
            "time is  517.7925040721893\n",
            "Round 10/40\n",
            "Layers to train: ['cblock21', 'cblock41', 'cblock12', 'ublock7transpose']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 464ms/step - accuracy: 0.7326 - loss: 0.7146\n",
            "Client 0 finished training with layers: ['cblock21', 'cblock41', 'cblock12', 'ublock7transpose', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 478ms/step - accuracy: 0.7304 - loss: 0.7176\n",
            "Client 1 finished training with layers: ['cblock21', 'cblock41', 'cblock12', 'ublock7transpose', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 475ms/step - accuracy: 0.7258 - loss: 0.7255\n",
            "Client 2 finished training with layers: ['cblock21', 'cblock41', 'cblock12', 'ublock7transpose', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock12', 'cblock21', 'cblock41', 'ublock7transpose', 'conv9', 'conv10'])\n",
            "Completed Round 10. Global model updated with layers: ['cblock21', 'cblock41', 'cblock12', 'ublock7transpose', 'conv9', 'conv10']at time\n",
            "time is  567.4896342754364\n",
            "Round 11/40\n",
            "Layers to train: ['ublock8transpose', 'cblock11', 'ublock91', 'ublock71']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 469ms/step - accuracy: 0.7348 - loss: 0.7053\n",
            "Client 0 finished training with layers: ['ublock8transpose', 'cblock11', 'ublock91', 'ublock71', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 532ms/step - accuracy: 0.7345 - loss: 0.7037\n",
            "Client 1 finished training with layers: ['ublock8transpose', 'cblock11', 'ublock91', 'ublock71', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 467ms/step - accuracy: 0.7281 - loss: 0.7163\n",
            "Client 2 finished training with layers: ['ublock8transpose', 'cblock11', 'ublock91', 'ublock71', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock11', 'ublock71', 'ublock8transpose', 'ublock91', 'conv9', 'conv10'])\n",
            "Completed Round 11. Global model updated with layers: ['ublock8transpose', 'cblock11', 'ublock91', 'ublock71', 'conv9', 'conv10']at time\n",
            "time is  625.660395860672\n",
            "Round 12/40\n",
            "Layers to train: ['ublock61', 'ublock6transpose', 'cblock42', 'ublock92']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 465ms/step - accuracy: 0.7382 - loss: 0.6942\n",
            "Client 0 finished training with layers: ['ublock61', 'ublock6transpose', 'cblock42', 'ublock92', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 442ms/step - accuracy: 0.7382 - loss: 0.6911\n",
            "Client 1 finished training with layers: ['ublock61', 'ublock6transpose', 'cblock42', 'ublock92', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 451ms/step - accuracy: 0.7341 - loss: 0.6987\n",
            "Client 2 finished training with layers: ['ublock61', 'ublock6transpose', 'cblock42', 'ublock92', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock42', 'ublock6transpose', 'ublock61', 'ublock92', 'conv9', 'conv10'])\n",
            "Completed Round 12. Global model updated with layers: ['ublock61', 'ublock6transpose', 'cblock42', 'ublock92', 'conv9', 'conv10']at time\n",
            "time is  681.7900722026825\n",
            "Round 13/40\n",
            "Layers to train: ['cblock42', 'cblock51', 'cblock32', 'ublock71']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 460ms/step - accuracy: 0.7447 - loss: 0.6772\n",
            "Client 0 finished training with layers: ['cblock42', 'cblock51', 'cblock32', 'ublock71', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 463ms/step - accuracy: 0.7411 - loss: 0.6843\n",
            "Client 1 finished training with layers: ['cblock42', 'cblock51', 'cblock32', 'ublock71', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 464ms/step - accuracy: 0.7334 - loss: 0.6994\n",
            "Client 2 finished training with layers: ['cblock42', 'cblock51', 'cblock32', 'ublock71', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock32', 'cblock42', 'cblock51', 'ublock71', 'conv9', 'conv10'])\n",
            "Completed Round 13. Global model updated with layers: ['cblock42', 'cblock51', 'cblock32', 'ublock71', 'conv9', 'conv10']at time\n",
            "time is  724.1202178001404\n",
            "Round 14/40\n",
            "Layers to train: ['ublock92', 'ublock71', 'cblock52', 'cblock31']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 467ms/step - accuracy: 0.7454 - loss: 0.6717\n",
            "Client 0 finished training with layers: ['ublock92', 'ublock71', 'cblock52', 'cblock31', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 454ms/step - accuracy: 0.7411 - loss: 0.6819\n",
            "Client 1 finished training with layers: ['ublock92', 'ublock71', 'cblock52', 'cblock31', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 461ms/step - accuracy: 0.7382 - loss: 0.6868\n",
            "Client 2 finished training with layers: ['ublock92', 'ublock71', 'cblock52', 'cblock31', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock31', 'cblock52', 'ublock71', 'ublock92', 'conv9', 'conv10'])\n",
            "Completed Round 14. Global model updated with layers: ['ublock92', 'ublock71', 'cblock52', 'cblock31', 'conv9', 'conv10']at time\n",
            "time is  780.3325831890106\n",
            "Round 15/40\n",
            "Layers to train: ['ublock92', 'cblock51', 'ublock9transpose', 'ublock91']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 533ms/step - accuracy: 0.7478 - loss: 0.6657\n",
            "Client 0 finished training with layers: ['ublock92', 'cblock51', 'ublock9transpose', 'ublock91', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 478ms/step - accuracy: 0.7446 - loss: 0.6695\n",
            "Client 1 finished training with layers: ['ublock92', 'cblock51', 'ublock9transpose', 'ublock91', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 474ms/step - accuracy: 0.7416 - loss: 0.6759\n",
            "Client 2 finished training with layers: ['ublock92', 'cblock51', 'ublock9transpose', 'ublock91', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock51', 'ublock9transpose', 'ublock91', 'ublock92', 'conv9', 'conv10'])\n",
            "Completed Round 15. Global model updated with layers: ['ublock92', 'cblock51', 'ublock9transpose', 'ublock91', 'conv9', 'conv10']at time\n",
            "time is  832.1191544532776\n",
            "Round 16/40\n",
            "Layers to train: ['cblock51', 'ublock8transpose', 'ublock91', 'cblock32']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 477ms/step - accuracy: 0.7505 - loss: 0.6543\n",
            "Client 0 finished training with layers: ['cblock51', 'ublock8transpose', 'ublock91', 'cblock32', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 473ms/step - accuracy: 0.7489 - loss: 0.6597\n",
            "Client 1 finished training with layers: ['cblock51', 'ublock8transpose', 'ublock91', 'cblock32', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 460ms/step - accuracy: 0.7453 - loss: 0.6661\n",
            "Client 2 finished training with layers: ['cblock51', 'ublock8transpose', 'ublock91', 'cblock32', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock32', 'cblock51', 'ublock8transpose', 'ublock91', 'conv9', 'conv10'])\n",
            "Completed Round 16. Global model updated with layers: ['cblock51', 'ublock8transpose', 'ublock91', 'cblock32', 'conv9', 'conv10']at time\n",
            "time is  895.2725765705109\n",
            "Round 17/40\n",
            "Layers to train: ['cblock12', 'cblock42', 'cblock51', 'cblock11']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 438ms/step - accuracy: 0.7528 - loss: 0.6475\n",
            "Client 0 finished training with layers: ['cblock12', 'cblock42', 'cblock51', 'cblock11', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 465ms/step - accuracy: 0.7490 - loss: 0.6581\n",
            "Client 1 finished training with layers: ['cblock12', 'cblock42', 'cblock51', 'cblock11', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 447ms/step - accuracy: 0.7448 - loss: 0.6635\n",
            "Client 2 finished training with layers: ['cblock12', 'cblock42', 'cblock51', 'cblock11', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock11', 'cblock12', 'cblock42', 'cblock51', 'conv9', 'conv10'])\n",
            "Completed Round 17. Global model updated with layers: ['cblock12', 'cblock42', 'cblock51', 'cblock11', 'conv9', 'conv10']at time\n",
            "time is  958.8982119560242\n",
            "Round 18/40\n",
            "Layers to train: ['cblock52', 'ublock61', 'cblock22', 'ublock82']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 462ms/step - accuracy: 0.7563 - loss: 0.6387\n",
            "Client 0 finished training with layers: ['cblock52', 'ublock61', 'cblock22', 'ublock82', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 526ms/step - accuracy: 0.7529 - loss: 0.6465\n",
            "Client 1 finished training with layers: ['cblock52', 'ublock61', 'cblock22', 'ublock82', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 473ms/step - accuracy: 0.7488 - loss: 0.6562\n",
            "Client 2 finished training with layers: ['cblock52', 'ublock61', 'cblock22', 'ublock82', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock22', 'cblock52', 'ublock61', 'ublock82', 'conv9', 'conv10'])\n",
            "Completed Round 18. Global model updated with layers: ['cblock52', 'ublock61', 'cblock22', 'ublock82', 'conv9', 'conv10']at time\n",
            "time is  1008.574079990387\n",
            "Round 19/40\n",
            "Layers to train: ['ublock92', 'cblock42', 'cblock12', 'ublock6transpose']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 470ms/step - accuracy: 0.7551 - loss: 0.6393\n",
            "Client 0 finished training with layers: ['ublock92', 'cblock42', 'cblock12', 'ublock6transpose', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 468ms/step - accuracy: 0.7535 - loss: 0.6439\n",
            "Client 1 finished training with layers: ['ublock92', 'cblock42', 'cblock12', 'ublock6transpose', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 469ms/step - accuracy: 0.7512 - loss: 0.6475\n",
            "Client 2 finished training with layers: ['ublock92', 'cblock42', 'cblock12', 'ublock6transpose', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock12', 'cblock42', 'ublock6transpose', 'ublock92', 'conv9', 'conv10'])\n",
            "Completed Round 19. Global model updated with layers: ['ublock92', 'cblock42', 'cblock12', 'ublock6transpose', 'conv9', 'conv10']at time\n",
            "time is  1058.2696039676666\n",
            "Round 20/40\n",
            "Layers to train: ['ublock71', 'cblock12', 'ublock8transpose', 'cblock51']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 472ms/step - accuracy: 0.7568 - loss: 0.6342\n",
            "Client 0 finished training with layers: ['ublock71', 'cblock12', 'ublock8transpose', 'cblock51', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 470ms/step - accuracy: 0.7533 - loss: 0.6423\n",
            "Client 1 finished training with layers: ['ublock71', 'cblock12', 'ublock8transpose', 'cblock51', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 469ms/step - accuracy: 0.7527 - loss: 0.6439\n",
            "Client 2 finished training with layers: ['ublock71', 'cblock12', 'ublock8transpose', 'cblock51', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock12', 'cblock51', 'ublock71', 'ublock8transpose', 'conv9', 'conv10'])\n",
            "Completed Round 20. Global model updated with layers: ['ublock71', 'cblock12', 'ublock8transpose', 'cblock51', 'conv9', 'conv10']at time\n",
            "time is  1107.9199635982513\n",
            "Round 21/40\n",
            "Layers to train: ['ublock72', 'ublock82', 'ublock9transpose', 'cblock31']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 463ms/step - accuracy: 0.7588 - loss: 0.6292\n",
            "Client 0 finished training with layers: ['ublock72', 'ublock82', 'ublock9transpose', 'cblock31', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 439ms/step - accuracy: 0.7567 - loss: 0.6343\n",
            "Client 1 finished training with layers: ['ublock72', 'ublock82', 'ublock9transpose', 'cblock31', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 457ms/step - accuracy: 0.7539 - loss: 0.6399\n",
            "Client 2 finished training with layers: ['ublock72', 'ublock82', 'ublock9transpose', 'cblock31', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock31', 'ublock72', 'ublock82', 'ublock9transpose', 'conv9', 'conv10'])\n",
            "Completed Round 21. Global model updated with layers: ['ublock72', 'ublock82', 'ublock9transpose', 'cblock31', 'conv9', 'conv10']at time\n",
            "time is  1164.1803450584412\n",
            "Round 22/40\n",
            "Layers to train: ['cblock42', 'ublock62', 'cblock41', 'cblock32']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 525ms/step - accuracy: 0.7609 - loss: 0.6227\n",
            "Client 0 finished training with layers: ['cblock42', 'ublock62', 'cblock41', 'cblock32', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 465ms/step - accuracy: 0.7588 - loss: 0.6279\n",
            "Client 1 finished training with layers: ['cblock42', 'ublock62', 'cblock41', 'cblock32', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 459ms/step - accuracy: 0.7540 - loss: 0.6385\n",
            "Client 2 finished training with layers: ['cblock42', 'ublock62', 'cblock41', 'cblock32', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock32', 'cblock41', 'cblock42', 'ublock62', 'conv9', 'conv10'])\n",
            "Completed Round 22. Global model updated with layers: ['cblock42', 'ublock62', 'cblock41', 'cblock32', 'conv9', 'conv10']at time\n",
            "time is  1213.4470708370209\n",
            "Round 23/40\n",
            "Layers to train: ['cblock11', 'ublock9transpose', 'ublock6transpose', 'ublock91']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 468ms/step - accuracy: 0.7618 - loss: 0.6225\n",
            "Client 0 finished training with layers: ['cblock11', 'ublock9transpose', 'ublock6transpose', 'ublock91', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 470ms/step - accuracy: 0.7601 - loss: 0.6239\n",
            "Client 1 finished training with layers: ['cblock11', 'ublock9transpose', 'ublock6transpose', 'ublock91', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 462ms/step - accuracy: 0.7569 - loss: 0.6317\n",
            "Client 2 finished training with layers: ['cblock11', 'ublock9transpose', 'ublock6transpose', 'ublock91', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock11', 'ublock6transpose', 'ublock9transpose', 'ublock91', 'conv9', 'conv10'])\n",
            "Completed Round 23. Global model updated with layers: ['cblock11', 'ublock9transpose', 'ublock6transpose', 'ublock91', 'conv9', 'conv10']at time\n",
            "time is  1276.5770194530487\n",
            "Round 24/40\n",
            "Layers to train: ['cblock22', 'ublock72', 'cblock51', 'ublock81']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 471ms/step - accuracy: 0.7620 - loss: 0.6209\n",
            "Client 0 finished training with layers: ['cblock22', 'ublock72', 'cblock51', 'ublock81', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 447ms/step - accuracy: 0.7595 - loss: 0.6250\n",
            "Client 1 finished training with layers: ['cblock22', 'ublock72', 'cblock51', 'ublock81', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 449ms/step - accuracy: 0.7577 - loss: 0.6288\n",
            "Client 2 finished training with layers: ['cblock22', 'ublock72', 'cblock51', 'ublock81', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock22', 'cblock51', 'ublock72', 'ublock81', 'conv9', 'conv10'])\n",
            "Completed Round 24. Global model updated with layers: ['cblock22', 'ublock72', 'cblock51', 'ublock81', 'conv9', 'conv10']at time\n",
            "time is  1325.8356943130493\n",
            "Round 25/40\n",
            "Layers to train: ['cblock32', 'ublock9transpose', 'cblock21', 'cblock31']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 444ms/step - accuracy: 0.7641 - loss: 0.6146\n",
            "Client 0 finished training with layers: ['cblock32', 'ublock9transpose', 'cblock21', 'cblock31', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 450ms/step - accuracy: 0.7623 - loss: 0.6172\n",
            "Client 1 finished training with layers: ['cblock32', 'ublock9transpose', 'cblock21', 'cblock31', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 502ms/step - accuracy: 0.7562 - loss: 0.6287\n",
            "Client 2 finished training with layers: ['cblock32', 'ublock9transpose', 'cblock21', 'cblock31', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock21', 'cblock31', 'cblock32', 'ublock9transpose', 'conv9', 'conv10'])\n",
            "Completed Round 25. Global model updated with layers: ['cblock32', 'ublock9transpose', 'cblock21', 'cblock31', 'conv9', 'conv10']at time\n",
            "time is  1376.7830946445465\n",
            "Round 26/40\n",
            "Layers to train: ['ublock61', 'ublock91', 'cblock52', 'cblock21']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 480ms/step - accuracy: 0.7672 - loss: 0.6073\n",
            "Client 0 finished training with layers: ['ublock61', 'ublock91', 'cblock52', 'cblock21', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 472ms/step - accuracy: 0.7633 - loss: 0.6140\n",
            "Client 1 finished training with layers: ['ublock61', 'ublock91', 'cblock52', 'cblock21', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 478ms/step - accuracy: 0.7623 - loss: 0.6169\n",
            "Client 2 finished training with layers: ['ublock61', 'ublock91', 'cblock52', 'cblock21', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock21', 'cblock52', 'ublock61', 'ublock91', 'conv9', 'conv10'])\n",
            "Completed Round 26. Global model updated with layers: ['ublock61', 'ublock91', 'cblock52', 'cblock21', 'conv9', 'conv10']at time\n",
            "time is  1439.9361996650696\n",
            "Round 27/40\n",
            "Layers to train: ['ublock62', 'ublock6transpose', 'cblock12', 'ublock91']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 464ms/step - accuracy: 0.7659 - loss: 0.6086\n",
            "Client 0 finished training with layers: ['ublock62', 'ublock6transpose', 'cblock12', 'ublock91', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 463ms/step - accuracy: 0.7635 - loss: 0.6146\n",
            "Client 1 finished training with layers: ['ublock62', 'ublock6transpose', 'cblock12', 'ublock91', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 471ms/step - accuracy: 0.7636 - loss: 0.6159\n",
            "Client 2 finished training with layers: ['ublock62', 'ublock6transpose', 'cblock12', 'ublock91', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock12', 'ublock6transpose', 'ublock62', 'ublock91', 'conv9', 'conv10'])\n",
            "Completed Round 27. Global model updated with layers: ['ublock62', 'ublock6transpose', 'cblock12', 'ublock91', 'conv9', 'conv10']at time\n",
            "time is  1489.3631229400635\n",
            "Round 28/40\n",
            "Layers to train: ['ublock81', 'ublock92', 'ublock61', 'cblock41']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 447ms/step - accuracy: 0.7663 - loss: 0.6064\n",
            "Client 0 finished training with layers: ['ublock81', 'ublock92', 'ublock61', 'cblock41', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 455ms/step - accuracy: 0.7664 - loss: 0.6075\n",
            "Client 1 finished training with layers: ['ublock81', 'ublock92', 'ublock61', 'cblock41', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 464ms/step - accuracy: 0.7621 - loss: 0.6153\n",
            "Client 2 finished training with layers: ['ublock81', 'ublock92', 'ublock61', 'cblock41', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock41', 'ublock61', 'ublock81', 'ublock92', 'conv9', 'conv10'])\n",
            "Completed Round 28. Global model updated with layers: ['ublock81', 'ublock92', 'ublock61', 'cblock41', 'conv9', 'conv10']at time\n",
            "time is  1545.8694021701813\n",
            "Round 29/40\n",
            "Layers to train: ['cblock31', 'cblock41', 'ublock62', 'ublock6transpose']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 523ms/step - accuracy: 0.7684 - loss: 0.6008\n",
            "Client 0 finished training with layers: ['cblock31', 'cblock41', 'ublock62', 'ublock6transpose', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 480ms/step - accuracy: 0.7666 - loss: 0.6066\n",
            "Client 1 finished training with layers: ['cblock31', 'cblock41', 'ublock62', 'ublock6transpose', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 477ms/step - accuracy: 0.7628 - loss: 0.6106\n",
            "Client 2 finished training with layers: ['cblock31', 'cblock41', 'ublock62', 'ublock6transpose', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock31', 'cblock41', 'ublock6transpose', 'ublock62', 'conv9', 'conv10'])\n",
            "Completed Round 29. Global model updated with layers: ['cblock31', 'cblock41', 'ublock62', 'ublock6transpose', 'conv9', 'conv10']at time\n",
            "time is  1603.042148590088\n",
            "Round 30/40\n",
            "Layers to train: ['ublock8transpose', 'ublock92', 'ublock91', 'cblock42']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 479ms/step - accuracy: 0.7701 - loss: 0.5970\n",
            "Client 0 finished training with layers: ['ublock8transpose', 'ublock92', 'ublock91', 'cblock42', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 473ms/step - accuracy: 0.7676 - loss: 0.6003\n",
            "Client 1 finished training with layers: ['ublock8transpose', 'ublock92', 'ublock91', 'cblock42', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 480ms/step - accuracy: 0.7670 - loss: 0.6018\n",
            "Client 2 finished training with layers: ['ublock8transpose', 'ublock92', 'ublock91', 'cblock42', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock42', 'ublock8transpose', 'ublock91', 'ublock92', 'conv9', 'conv10'])\n",
            "Completed Round 30. Global model updated with layers: ['ublock8transpose', 'ublock92', 'ublock91', 'cblock42', 'conv9', 'conv10']at time\n",
            "time is  1659.7770292758942\n",
            "Round 31/40\n",
            "Layers to train: ['cblock51', 'ublock72', 'ublock9transpose', 'ublock7transpose']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 481ms/step - accuracy: 0.7729 - loss: 0.5907\n",
            "Client 0 finished training with layers: ['cblock51', 'ublock72', 'ublock9transpose', 'ublock7transpose', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 475ms/step - accuracy: 0.7713 - loss: 0.5927\n",
            "Client 1 finished training with layers: ['cblock51', 'ublock72', 'ublock9transpose', 'ublock7transpose', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 474ms/step - accuracy: 0.7632 - loss: 0.6119\n",
            "Client 2 finished training with layers: ['cblock51', 'ublock72', 'ublock9transpose', 'ublock7transpose', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock51', 'ublock7transpose', 'ublock72', 'ublock9transpose', 'conv9', 'conv10'])\n",
            "Completed Round 31. Global model updated with layers: ['cblock51', 'ublock72', 'ublock9transpose', 'ublock7transpose', 'conv9', 'conv10']at time\n",
            "time is  1716.4248585700989\n",
            "Round 32/40\n",
            "Layers to train: ['cblock51', 'ublock8transpose', 'ublock81', 'ublock91']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 466ms/step - accuracy: 0.7727 - loss: 0.5876\n",
            "Client 0 finished training with layers: ['cblock51', 'ublock8transpose', 'ublock81', 'ublock91', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 534ms/step - accuracy: 0.7715 - loss: 0.5918\n",
            "Client 1 finished training with layers: ['cblock51', 'ublock8transpose', 'ublock81', 'ublock91', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 472ms/step - accuracy: 0.7700 - loss: 0.5943\n",
            "Client 2 finished training with layers: ['cblock51', 'ublock8transpose', 'ublock81', 'ublock91', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock51', 'ublock8transpose', 'ublock81', 'ublock91', 'conv9', 'conv10'])\n",
            "Completed Round 32. Global model updated with layers: ['cblock51', 'ublock8transpose', 'ublock81', 'ublock91', 'conv9', 'conv10']at time\n",
            "time is  1772.8011453151703\n",
            "Round 33/40\n",
            "Layers to train: ['cblock42', 'cblock21', 'ublock72', 'cblock51']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 474ms/step - accuracy: 0.7727 - loss: 0.5884\n",
            "Client 0 finished training with layers: ['cblock42', 'cblock21', 'ublock72', 'cblock51', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 476ms/step - accuracy: 0.7713 - loss: 0.5901\n",
            "Client 1 finished training with layers: ['cblock42', 'cblock21', 'ublock72', 'cblock51', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 453ms/step - accuracy: 0.7655 - loss: 0.6032\n",
            "Client 2 finished training with layers: ['cblock42', 'cblock21', 'ublock72', 'cblock51', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock21', 'cblock42', 'cblock51', 'ublock72', 'conv9', 'conv10'])\n",
            "Completed Round 33. Global model updated with layers: ['cblock42', 'cblock21', 'ublock72', 'cblock51', 'conv9', 'conv10']at time\n",
            "time is  1822.5969495773315\n",
            "Round 34/40\n",
            "Layers to train: ['ublock9transpose', 'cblock21', 'cblock11', 'ublock8transpose']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 450ms/step - accuracy: 0.7746 - loss: 0.5821\n",
            "Client 0 finished training with layers: ['ublock9transpose', 'cblock21', 'cblock11', 'ublock8transpose', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 466ms/step - accuracy: 0.7739 - loss: 0.5864\n",
            "Client 1 finished training with layers: ['ublock9transpose', 'cblock21', 'cblock11', 'ublock8transpose', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 439ms/step - accuracy: 0.7711 - loss: 0.5889\n",
            "Client 2 finished training with layers: ['ublock9transpose', 'cblock21', 'cblock11', 'ublock8transpose', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock11', 'cblock21', 'ublock8transpose', 'ublock9transpose', 'conv9', 'conv10'])\n",
            "Completed Round 34. Global model updated with layers: ['ublock9transpose', 'cblock21', 'cblock11', 'ublock8transpose', 'conv9', 'conv10']at time\n",
            "time is  1878.8131687641144\n",
            "Round 35/40\n",
            "Layers to train: ['ublock81', 'ublock8transpose', 'ublock62', 'cblock51']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 460ms/step - accuracy: 0.7744 - loss: 0.5833\n",
            "Client 0 finished training with layers: ['ublock81', 'ublock8transpose', 'ublock62', 'cblock51', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 493ms/step - accuracy: 0.7761 - loss: 0.5797\n",
            "Client 1 finished training with layers: ['ublock81', 'ublock8transpose', 'ublock62', 'cblock51', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 517ms/step - accuracy: 0.7723 - loss: 0.5855\n",
            "Client 2 finished training with layers: ['ublock81', 'ublock8transpose', 'ublock62', 'cblock51', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock51', 'ublock62', 'ublock8transpose', 'ublock81', 'conv9', 'conv10'])\n",
            "Completed Round 35. Global model updated with layers: ['ublock81', 'ublock8transpose', 'ublock62', 'cblock51', 'conv9', 'conv10']at time\n",
            "time is  1929.7521290779114\n",
            "Round 36/40\n",
            "Layers to train: ['ublock92', 'ublock81', 'ublock72', 'ublock82']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 493ms/step - accuracy: 0.7775 - loss: 0.5770\n",
            "Client 0 finished training with layers: ['ublock92', 'ublock81', 'ublock72', 'ublock82', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 484ms/step - accuracy: 0.7759 - loss: 0.5819\n",
            "Client 1 finished training with layers: ['ublock92', 'ublock81', 'ublock72', 'ublock82', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 480ms/step - accuracy: 0.7732 - loss: 0.5833\n",
            "Client 2 finished training with layers: ['ublock92', 'ublock81', 'ublock72', 'ublock82', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['ublock72', 'ublock81', 'ublock82', 'ublock92', 'conv9', 'conv10'])\n",
            "Completed Round 36. Global model updated with layers: ['ublock92', 'ublock81', 'ublock72', 'ublock82', 'conv9', 'conv10']at time\n",
            "time is  1992.8777832984924\n",
            "Round 37/40\n",
            "Layers to train: ['ublock6transpose', 'ublock9transpose', 'ublock7transpose', 'ublock91']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 487ms/step - accuracy: 0.7780 - loss: 0.5727\n",
            "Client 0 finished training with layers: ['ublock6transpose', 'ublock9transpose', 'ublock7transpose', 'ublock91', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 484ms/step - accuracy: 0.7764 - loss: 0.5787\n",
            "Client 1 finished training with layers: ['ublock6transpose', 'ublock9transpose', 'ublock7transpose', 'ublock91', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 478ms/step - accuracy: 0.7746 - loss: 0.5813\n",
            "Client 2 finished training with layers: ['ublock6transpose', 'ublock9transpose', 'ublock7transpose', 'ublock91', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['ublock6transpose', 'ublock7transpose', 'ublock9transpose', 'ublock91', 'conv9', 'conv10'])\n",
            "Completed Round 37. Global model updated with layers: ['ublock6transpose', 'ublock9transpose', 'ublock7transpose', 'ublock91', 'conv9', 'conv10']at time\n",
            "time is  2043.3621292114258\n",
            "Round 38/40\n",
            "Layers to train: ['cblock51', 'ublock61', 'cblock31', 'ublock7transpose']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 480ms/step - accuracy: 0.7787 - loss: 0.5743\n",
            "Client 0 finished training with layers: ['cblock51', 'ublock61', 'cblock31', 'ublock7transpose', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 479ms/step - accuracy: 0.7762 - loss: 0.5784\n",
            "Client 1 finished training with layers: ['cblock51', 'ublock61', 'cblock31', 'ublock7transpose', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 483ms/step - accuracy: 0.7762 - loss: 0.5774\n",
            "Client 2 finished training with layers: ['cblock51', 'ublock61', 'cblock31', 'ublock7transpose', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock31', 'cblock51', 'ublock61', 'ublock7transpose', 'conv9', 'conv10'])\n",
            "Completed Round 38. Global model updated with layers: ['cblock51', 'ublock61', 'cblock31', 'ublock7transpose', 'conv9', 'conv10']at time\n",
            "time is  2100.038090467453\n",
            "Round 39/40\n",
            "Layers to train: ['cblock42', 'ublock9transpose', 'cblock52', 'cblock11']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 530ms/step - accuracy: 0.7791 - loss: 0.5698\n",
            "Client 0 finished training with layers: ['cblock42', 'ublock9transpose', 'cblock52', 'cblock11', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 479ms/step - accuracy: 0.7742 - loss: 0.5848\n",
            "Client 1 finished training with layers: ['cblock42', 'ublock9transpose', 'cblock52', 'cblock11', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 455ms/step - accuracy: 0.7765 - loss: 0.5765\n",
            "Client 2 finished training with layers: ['cblock42', 'ublock9transpose', 'cblock52', 'cblock11', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock11', 'cblock42', 'cblock52', 'ublock9transpose', 'conv9', 'conv10'])\n",
            "Completed Round 39. Global model updated with layers: ['cblock42', 'ublock9transpose', 'cblock52', 'cblock11', 'conv9', 'conv10']at time\n",
            "time is  2156.833366394043\n",
            "Round 40/40\n",
            "Layers to train: ['cblock31', 'cblock11', 'ublock72', 'ublock8transpose']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 465ms/step - accuracy: 0.7791 - loss: 0.5703\n",
            "Client 0 finished training with layers: ['cblock31', 'cblock11', 'ublock72', 'ublock8transpose', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 474ms/step - accuracy: 0.7779 - loss: 0.5735\n",
            "Client 1 finished training with layers: ['cblock31', 'cblock11', 'ublock72', 'ublock8transpose', 'conv9', 'conv10']\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 462ms/step - accuracy: 0.7722 - loss: 0.5873\n",
            "Client 2 finished training with layers: ['cblock31', 'cblock11', 'ublock72', 'ublock8transpose', 'conv9', 'conv10']\n",
            "new_weights dict_keys(['cblock11', 'cblock31', 'ublock72', 'ublock8transpose', 'conv9', 'conv10'])\n",
            "Completed Round 40. Global model updated with layers: ['cblock31', 'cblock11', 'ublock72', 'ublock8transpose', 'conv9', 'conv10']at time\n",
            "time is  2207.5107979774475\n",
            "time is  2208.282042503357\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 3s/step - accuracy: 0.7715 - loss: 0.6135\n",
            "Final evaluation on Client 4's dataset - Loss: 0.6120059490203857, Accuracy: 0.7724840641021729\n"
          ]
        }
      ],
      "source": [
        "# Initialize the global model\n",
        "import time\n",
        "import random\n",
        "from tensorflow.keras import backend as K\n",
        "import gc\n",
        "global_model = UNetCompiled(input_size=(128, 128, 3), n_filters=32, n_classes=3)\n",
        "global_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                     loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                     metrics=['accuracy'])\n",
        "# List all layer names\n",
        "all_layer_names = [layer.name for layer in global_model.layers]\n",
        "\n",
        "num_rounds = 40\n",
        "\n",
        "# Clients create a local model initially (in round 0)\n",
        "client_models = []\n",
        "for _ in range(len(client_datasets)-1):\n",
        "    client_model = tf.keras.models.clone_model(global_model)\n",
        "    client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n",
        "    client_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                     loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                     metrics=['accuracy'])\n",
        "    client_models.append(client_model)\n",
        "\n",
        "# Initialize the layers to send for the first round\n",
        "layers_to_send = []  # No layers to send initially\n",
        "start_time = time.time()\n",
        "for round_num in range(num_rounds):\n",
        "    print(f\"Round {round_num + 1}/{num_rounds}\")\n",
        "\n",
        "    # Randomly select layers to train for this round\n",
        "    layers_to_train = random.sample(layer_names, 4)  # Example: select 2 random layers\n",
        "    print(\"Layers to train:\", layers_to_train)\n",
        "\n",
        "    # Include specific layers (e.g., output layers) that should always be trained\n",
        "    layers_to_train.append('conv9')\n",
        "    layers_to_train.append('conv10')\n",
        "\n",
        "    # Server sends weights of the selected layers from the previous round to clients\n",
        "    layer_weights_to_send = get_layer_weights(global_model, layers_to_send) if layers_to_send else None\n",
        "\n",
        "    client_weights = []\n",
        "    client_layers = []\n",
        "\n",
        "    # Each client trains its local model with the specified layers\n",
        "    for client_id, client_dataset in enumerate(client_datasets[0:(len(client_datasets)-1)]):\n",
        "        client_model = client_models[client_id]  # Reuse the local model created in round 0\n",
        "\n",
        "        if layer_weights_to_send:\n",
        "            # Update only the relevant layers for this round\n",
        "\n",
        "            update_layer_weights(client_model, layer_weights_to_send)\n",
        "\n",
        "\n",
        "        # Set the specified layers to be trainable\n",
        "        set_trainable_layers(client_model, layers_to_train)\n",
        "\n",
        "        # Compile and train the local model on the client's dataset\n",
        "        client_model.fit(client_dataset, epochs=1)\n",
        "        print(f\"Client {client_id} finished training with layers: {layers_to_train}\")\n",
        "\n",
        "        # Collect only the updated weights for the trained layers\n",
        "        updated_weights = get_layer_weights(client_model, layers_to_train)\n",
        "        client_weights.append(updated_weights)\n",
        "        client_layers.append(layers_to_train)\n",
        "\n",
        "    # Perform federated averaging with only the trained layers\n",
        "    avg_weights = federated_averaging(client_weights, client_layers)\n",
        "    # Update the global model with the averaged weights\n",
        "    update_layer_weights(global_model, avg_weights)\n",
        "\n",
        "    # Prepare the layers for the next round\n",
        "    layers_to_send = layers_to_train\n",
        "\n",
        "    print(f\"Completed Round {round_num + 1}. Global model updated with layers: {layers_to_train}at time\")\n",
        "    print(\"time is \",(time.time()-start_time))\n",
        "    del client_weights, client_layers\n",
        "    K.clear_session()\n",
        "\n",
        "    # Force garbage collection to prevent memory from accumulating\n",
        "    gc.collect()\n",
        "\n",
        "print(\"time is \",(time.time()-start_time))\n",
        "# Evaluate on client 4's dataset\n",
        "loss, accuracy = global_model.evaluate(client_datasets[-1])\n",
        "print(f\"Final evaluation on Client 4's dataset - Loss: {loss}, Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "By4Hjs1l_aYH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "\n",
        "# Number of clients\n",
        "num_clients = 5\n",
        "\n",
        "# Shuffle the dataset and divide it into num_clients parts\n",
        "client_data_indices = np.array_split(np.arange(len(img)), num_clients)\n",
        "\n",
        "# Create datasets for each client\n",
        "client_datasets = []\n",
        "for indices in client_data_indices:\n",
        "    client_images = np.array(img)[indices]\n",
        "    client_masks = np.array(mask)[indices]\n",
        "\n",
        "    # Create TensorFlow datasets for each client\n",
        "    client_dataset = tf.data.Dataset.from_tensor_slices((client_images, client_masks))\n",
        "    client_dataset = client_dataset.map(map_fn).batch(64).prefetch(1)\n",
        "    client_datasets.append(client_dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYcc6t0APGCE"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "global_model = UNetCompiled(input_size=(128, 128, 3), n_filters=32, n_classes=3)\n",
        "all_layer_names = [layer.name for layer in global_model.layers]\n",
        "\n",
        "def train_client_model(client_dataset, client_id, layers_to_train):\n",
        "    local_model = tf.keras.models.clone_model(global_model)\n",
        "    local_model.set_weights(global_model.get_weights())  # Copy global weights to the local model\n",
        "    set_trainable_layers(local_model, layers_to_train)\n",
        "    local_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                        metrics=['accuracy'])\n",
        "    local_model.fit(client_dataset, epochs=1)\n",
        "    print(f\"Client {client_id} finished training.\")\n",
        "    return local_model.get_weights(), layers_to_train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfZMBS0BPcof"
      },
      "outputs": [],
      "source": [
        "def federated_averaging(client_weights, client_layers):\n",
        "    new_weights = [np.zeros_like(w) for w in client_weights[0]]\n",
        "    for client_weight, layers_to_train in zip(client_weights, client_layers):\n",
        "        for i, layer_name in enumerate(all_layer_names):\n",
        "            if layer_name in layers_to_train:\n",
        "                new_weights[i] += client_weight[i]\n",
        "    new_weights = [w / len(client_weights) if all_layer_names[i] in set(sum(client_layers, [])) else w\n",
        "                   for i, w in enumerate(new_weights)]\n",
        "    return new_weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sk-NkAfDPgj5"
      },
      "outputs": [],
      "source": [
        "num_rounds = 10\n",
        "\n",
        "for round_num in range(num_rounds):\n",
        "    print(f\"Round {round_num + 1}/{num_rounds}\")\n",
        "\n",
        "    layers_to_train = random.sample(all_layer_names, 4)  # Example: select 4 random layers\n",
        "    layers_to_train.extend([\"conv9\", \"conv10\"])  # Always train specific layers\n",
        "    client_weights = []\n",
        "    client_layers = []\n",
        "    for client_id, client_dataset in enumerate(client_datasets):\n",
        "        client_weight, trained_layers = train_client_model(client_dataset, client_id, layers_to_train)\n",
        "        client_weights.append(client_weight)\n",
        "        client_layers.append(trained_layers)\n",
        "\n",
        "    avg_weights = federated_averaging(client_weights, client_layers)\n",
        "    global_model.set_weights(avg_weights)\n",
        "\n",
        "    print(f\"Completed Round {round_num + 1}. Global model updated with layers: {layers_to_train}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}